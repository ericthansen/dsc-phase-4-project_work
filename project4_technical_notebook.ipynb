{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Eric\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#must ensure conda install py-xgboost\n",
    "#import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>A littly iffy on the controls, but once you kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Great game, fun and colorful and all that.A si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Not many games have the cute tag right next to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                        title    year  \\\n",
       "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
       "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
       "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
       "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
       "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
       "\n",
       "                                         user_review  user_suggestion  \n",
       "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
       "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
       "2  A littly iffy on the controls, but once you kn...                1  \n",
       "3  Great game, fun and colorful and all that.A si...                1  \n",
       "4  Not many games have the cute tag right next to...                1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1603</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Nice graphics, new maps, weapons and models. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1604</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>I would not recommend getting into this at its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1605</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Edit 11/12/18I have tried playing CS:GO recent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1606</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>The game is great. But the community is the wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1607</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>I thank TrulyRazor for buying this for me a lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                             title    year  \\\n",
       "0       1603  Counter-Strike: Global Offensive  2015.0   \n",
       "1       1604  Counter-Strike: Global Offensive  2018.0   \n",
       "2       1605  Counter-Strike: Global Offensive  2018.0   \n",
       "3       1606  Counter-Strike: Global Offensive  2015.0   \n",
       "4       1607  Counter-Strike: Global Offensive  2015.0   \n",
       "\n",
       "                                         user_review  \n",
       "0  Nice graphics, new maps, weapons and models. B...  \n",
       "1  I would not recommend getting into this at its...  \n",
       "2  Edit 11/12/18I have tried playing CS:GO recent...  \n",
       "3  The game is great. But the community is the wo...  \n",
       "4  I thank TrulyRazor for buying this for me a lo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17494 entries, 0 to 17493\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   review_id        17494 non-null  int64  \n",
      " 1   title            17494 non-null  object \n",
      " 2   year             17316 non-null  float64\n",
      " 3   user_review      17494 non-null  object \n",
      " 4   user_suggestion  17494 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 683.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train_df.user_suggestion.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.user_review.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Models\n",
    "- TF-IDF\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following features are common starting points and work well in most cases.\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.384 \n",
      "f1 score: 0.879 \n",
      "Accuracy score: 0.858 \n"
     ]
    }
   ],
   "source": [
    "# Fit a simple Logistic Regression on TF-IDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "bin_preds = clf.predict(xvalid_tfv)\n",
    "# sklearn.metrics.log_loss(y_true, y_pred, *, eps=1e-15, normalize=True, sample_weight=None, labels=None)\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))\n",
    "#Note, we want to be careful about applying accuracy/f1 here because those are classification metrics, and only apply to the\n",
    "#binary outputs of .predict.  \n",
    "#We can apply the predict_proba to get actual probabilities (i.e. before the softmax step) that are possibly more\n",
    "#descriptive of what the regression is doing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using TF-IDF, we can also use word counts as features. This can be done easily using CountVectorizer from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_ctv =  ctv.transform(xtrain) \n",
    "xvalid_ctv = ctv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out an arbitrary entry of that ctv\n",
    "#xtrain_ctv[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.449 \n",
      "f1 score: 0.872 \n",
      "Accuracy score: 0.851 \n"
     ]
    }
   ],
   "source": [
    "# Fit a simple Logistic Regression on those Counts\n",
    "clf = LogisticRegression(C=1.0, max_iter=500,)\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "bin_preds = clf.predict(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, worse loss, f1, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.400 \n",
      "f1 score: 0.868 \n",
      "Accuracy score: 0.836 \n"
     ]
    }
   ],
   "source": [
    "# Fitt a simple Naive Bayes on TF-IDF\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "bin_preds = clf.predict(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!  Naive Bayes improved loss!     \n",
    "\n",
    "Accuracy and F1 took a hit though, but the improvement in loss implies that the model is overall better at describing things.  \n",
    "\n",
    "What happens when we use this model on counts data instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.286 \n",
      "f1 score: 0.876 \n",
      "Accuracy score: 0.859 \n"
     ]
    }
   ],
   "source": [
    "# Fit a simple Naive Bayes on Counts\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "bin_preds = clf.predict(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB on counts did worse on loss, but held ground on F1 and Acc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more classic algorithm is SVMs. \n",
    "\n",
    "In order to improve performance on time, we will reduce the number of features from the TF-IDF using Singular Value Decomposition before applying SVM.\n",
    "\n",
    "Also, it is better to standardize the data before applying SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SVD, with 120 components. 120-200 components are widely considered sufficient for SVM.\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(xtrain_tfv)\n",
    "xtrain_svd = svd.transform(xtrain_tfv)\n",
    "xvalid_svd = svd.transform(xvalid_tfv)\n",
    "\n",
    "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(xtrain_svd)\n",
    "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
    "xvalid_svd_scl = scl.transform(xvalid_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now time to fit the SVM.  This can take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.368 \n",
      "f1 score: 0.858 \n",
      "Accuracy score: 0.835 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple SVM\n",
    "clf = SVC(C=1.0, probability=True) # since we want probabilities in addition to the 0/1 scores\n",
    "clf.fit(xtrain_svd_scl, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)\n",
    "bin_preds = clf.predict(xvalid_svd_scl)\n",
    "\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even better loss and good f1/acc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That performed pretty well on logloss.  Neat!  \n",
    "\n",
    "Of course, we couldn't stop without trying XGBoost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.393 \n",
      "f1 score: 0.856 \n",
      "Accuracy score: 0.831 \n"
     ]
    }
   ],
   "source": [
    "# Fit a basic xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
    "bin_preds = clf.predict(xvalid_tfv.tocsc())\n",
    "\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely, XGBoost didn't do as well on TF-IDF features as logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:55] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logloss: 0.411 \n",
      "f1 score: 0.758 \n",
      "Accuracy score: 0.707 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features with default parameters\n",
    "clf = xgb.XGBClassifier(nthread=10)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "bin_preds = clf.predict(xvalid_svd_scl)\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logloss: 0.390 \n",
      "f1 score: 0.847 \n",
      "Accuracy score: 0.823 \n"
     ]
    }
   ],
   "source": [
    "# Fit a basic xgboost on more common hyperparams for tf-idf svd features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "bin_preds = clf.predict(xvalid_svd)\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On TF-IDF SVD unscaled features, XGBoost does not improve.  \n",
    "\n",
    "What about on scaled features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:54:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logloss: 0.390 \n",
      "f1 score: 0.847 \n",
      "Accuracy score: 0.823 \n"
     ]
    }
   ],
   "source": [
    "# Fit a basic xgboost on SCALED tf-idf svd features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_svd_scl, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)\n",
    "bin_preds = clf.predict(xvalid_svd_scl)\n",
    "\n",
    "print (\"logloss: %0.3f \" % log_loss(yvalid, predictions))\n",
    "print (\"f1 score: %0.3f \" % f1_score(yvalid, bin_preds))\n",
    "print (\"Accuracy score: %0.3f \" % accuracy_score(yvalid, bin_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And on Scaled TF-IDF SVD features, XGboost does very similarly.  \n",
    "\n",
    "But wait!  We haven't done any tuning of hyperparameters yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve all those models with some grid search optimization  \n",
    "First, we can define a scoring metric for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_scorer = metrics.make_scorer(log_loss, greater_is_better=False, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we applied svd and scaling to two different sets (TF-IDF and SVD), this seems like it has potential for a pipeline approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVD\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "# Initialize a standard scaler \n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "# We will use logistic regression here..\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create the Logistic Regression pipeline \n",
    "clf_lr = pipeline.Pipeline([('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('lr', lr_model)])\n",
    "\n",
    "#Here we can set up another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tfidf\\ncount features\\nlogistic regression\\nnaive bayes\\nsvm\\nxgboost\\ngrid search\\nword vectors\\nLSTM\\nGRU\\nEnsembling'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up apache spark system to do parallel processing?\n",
    "#maybe Try to set up amazon resources - possibly overkill/not good for github\n",
    "## see recommendation systems section - this isn't actually directly applicable - more for recs for a user based on other user's recs\n",
    "# topic 39 - nlp obvs\n",
    "#tf-idfs?\n",
    "#nnetworks with\n",
    "# word2vec (including gensim) see https://learning.flatironschool.com/courses/1890/pages/using-word2vec?module_item_id=261958\n",
    "#GloVe for classification - (This is a very good pretrained model)\n",
    "# word embeddings, \n",
    "#sequence models e.g. \n",
    "#RNN and \n",
    "#lstms, \n",
    "#grus, \n",
    "#gridsearch for best params,\n",
    "#ensemble methods - e.g. xgboost on these models\n",
    "#anything else that is in \n",
    "# https://www.kaggle.com/code/abhishek/approaching-almost-any-nlp-problem-on-kaggle/comments\n",
    "'''tfidf\n",
    "count features\n",
    "logistic regression\n",
    "naive bayes\n",
    "svm\n",
    "xgboost\n",
    "grid search\n",
    "word vectors\n",
    "LSTM\n",
    "GRU\n",
    "Ensembling'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
